{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine-tuning language part of model","metadata":{}},{"cell_type":"markdown","source":"### Installing requirements","metadata":{}},{"cell_type":"code","source":"!pip install -q --upgrade \\\n    pip \\\n    setuptools \\\n    wheel\n!pip install -q \\\n    torch \\\n    numpy \\\n    tqdm \\\n    \"transformers>=4.41.0\" \\\n    \"huggingface_hub>=0.23.2\" \\\n    peft \\\n    accelerate \\\n    matplotlib \\\n    git+https://github.com/tingofurro/summac \\\n    \"datasets<=2.14.6\"\n!pip install -q --upgrade bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:45:24.485530Z","iopub.execute_input":"2025-05-26T17:45:24.485773Z","iopub.status.idle":"2025-05-26T17:47:27.185008Z","shell.execute_reply.started":"2025-05-26T17:45:24.485754Z","shell.execute_reply":"2025-05-26T17:47:27.184271Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[33m  DEPRECATION: Building 'summac' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'summac'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n\u001b[0m  Building wheel for summac (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/14\u001b[0m [datasets]/14\u001b[0m [datasets]ers]er-cu12]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### Necessary imports","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoTokenizer, AutoModel, get_scheduler, BitsAndBytesConfig\nfrom datasets import load_dataset\nfrom peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, TaskType\nfrom accelerate import Accelerator\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:47:27.186471Z","iopub.execute_input":"2025-05-26T17:47:27.186715Z","iopub.status.idle":"2025-05-26T17:47:50.662898Z","shell.execute_reply.started":"2025-05-26T17:47:27.186692Z","shell.execute_reply":"2025-05-26T17:47:50.662131Z"}},"outputs":[{"name":"stderr","text":"2025-05-26 17:47:39.976598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748281660.178568      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748281660.233312      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Defining variables","metadata":{}},{"cell_type":"code","source":"MODEL_NAME = \"OpenGVLab/InternVL2_5-4B\"\nDATASET_NAME = \"RussianNLP/Mixed-Summarization-Dataset\"\nOUTPUT_DIR = \"./finetuned_model\"\nBATCH_SIZE = 4\nEPOCHS = 5\nLR = 2e-4  # learning rate\nMAX_LENGTH = 128  # maximum token length\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:47:50.663693Z","iopub.execute_input":"2025-05-26T17:47:50.664316Z","iopub.status.idle":"2025-05-26T17:47:50.668335Z","shell.execute_reply.started":"2025-05-26T17:47:50.664293Z","shell.execute_reply":"2025-05-26T17:47:50.667608Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### Uploading model and tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True, use_fast=True)\ntokenizer.padding_side = 'left'\n\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\n# Model 4bit с bnb\nfull_model = AutoModel.from_pretrained(\n    MODEL_NAME,\n    device_map='auto',\n    quantization_config=quantization_config,\n    trust_remote_code=True\n)\n\n# Connecting language part of model\nmodel = full_model.language_model\n# Preparing model for QLoRA\nmodel = prepare_model_for_kbit_training(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:47:50.669953Z","iopub.execute_input":"2025-05-26T17:47:50.670236Z","iopub.status.idle":"2025-05-26T17:48:28.844510Z","shell.execute_reply.started":"2025-05-26T17:47:50.670197Z","shell.execute_reply":"2025-05-26T17:48:28.843951Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/9.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b3e97f7b8194605b25382722a9c3665"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/3.38M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"454db8cfaeba456a87fd7341569bf35d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd1e5821e32c4421991d45601ae867ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/790 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"380b1b44741d4204928a9c5688c4d800"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/744 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f8e7bae1d3a42bdab931254d997b4de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/3.74k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72ff959cba4b4fce9e4045c49d742e4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_internvl_chat.py:   0%|          | 0.00/4.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f4dad8d6b034a64ad727b89591b8279"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_intern_vit.py:   0%|          | 0.00/5.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"560e19560d1141579c3285c967bd1fc9"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/OpenGVLab/InternVL2_5-4B:\n- configuration_intern_vit.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/OpenGVLab/InternVL2_5-4B:\n- configuration_internvl_chat.py\n- configuration_intern_vit.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_internvl_chat.py:   0%|          | 0.00/15.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ba6a16b61a746dfbb8ce3951170aa44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"conversation.py:   0%|          | 0.00/15.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bd60c97736e475c88347ce4097dec6a"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/OpenGVLab/InternVL2_5-4B:\n- conversation.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_intern_vit.py:   0%|          | 0.00/18.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcd8c915bfc24b74a5c13f59a9d49c33"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/OpenGVLab/InternVL2_5-4B:\n- modeling_intern_vit.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/OpenGVLab/InternVL2_5-4B:\n- modeling_internvl_chat.py\n- conversation.py\n- modeling_intern_vit.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n","output_type":"stream"},{"name":"stdout","text":"FlashAttention2 is not installed.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/71.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a1816c7b9a94a82bbebf77e680d9fed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcd48fd042de407b905be2b1503a5b27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ffd0b5bdbed45ffb06c21db6f170b8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.43G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e369c503503441b88dc71fb7c4dcb9c7"}},"metadata":{}},{"name":"stderr","text":"Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3678fed52b18421798c5bcc0be6511e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/129 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d0fcd3ef87a4d69b5dafa9314ec6a5b"}},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"### LoRA configuration","metadata":{}},{"cell_type":"code","source":"# Configuration for QLoRA fine-tuning\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],  # for LLMs\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=TaskType.CAUSAL_LM,\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:48:28.845138Z","iopub.execute_input":"2025-05-26T17:48:28.845350Z","iopub.status.idle":"2025-05-26T17:48:29.301727Z","shell.execute_reply.started":"2025-05-26T17:48:28.845327Z","shell.execute_reply":"2025-05-26T17:48:29.301131Z"}},"outputs":[{"name":"stdout","text":"trainable params: 14,966,784 || all params: 3,410,997,248 || trainable%: 0.4388\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### Preparing the dataset","metadata":{}},{"cell_type":"code","source":"train_data = load_dataset(DATASET_NAME, split='train')\n\ntrain_data = train_data.select(range(10000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:48:29.302342Z","iopub.execute_input":"2025-05-26T17:48:29.302552Z","iopub.status.idle":"2025-05-26T17:48:42.155835Z","shell.execute_reply.started":"2025-05-26T17:48:29.302537Z","shell.execute_reply":"2025-05-26T17:48:42.155299Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22396d4d11ee4969b6ab07b080956007"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13a8247af362412290467d3470d89ef3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/538M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69d40704244741c08d9cbc5b5670cc47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/605k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd1c2e15b6034311bb6fa359e5046ef9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54ee53c7778446cdbc610d5a9169d67d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/197561 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8124f21a55614becae399dd86d4a47d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/258 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0561ca78a2c4fa59320d3832b26816a"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n  table = cls._concat_blocks(blocks, axis=0)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### Preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocess_function(examples):\n    inputs = examples[\"text\"]\n    targets = examples[\"summary\"]\n    model_inputs = tokenizer(inputs, max_length=MAX_LENGTH, padding=\"max_length\", truncation=True)  # no return_tensors=\"pt\"\n    labels = tokenizer(targets, max_length=MAX_LENGTH, padding=\"max_length\", truncation=True)[\"input_ids\"]\n    # replace pad tokens with -100 in labels (for ignoring in loss)\n    labels = [[(token if token != tokenizer.pad_token_id else -100) for token in label] for label in labels]\n    model_inputs[\"labels\"] = labels\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:48:42.156646Z","iopub.execute_input":"2025-05-26T17:48:42.156941Z","iopub.status.idle":"2025-05-26T17:48:42.161577Z","shell.execute_reply.started":"2025-05-26T17:48:42.156915Z","shell.execute_reply":"2025-05-26T17:48:42.160842Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"processed_dataset = train_data.map(\n    preprocess_function,\n    batched=True,\n    batch_size=16,\n    remove_columns=train_data.column_names,\n    load_from_cache_file=False\n)\n\n# Splitting on training/validation\nsplit = processed_dataset.train_test_split(test_size=0.1)\ntrain_dataset = split[\"train\"]\nval_dataset = split[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:48:42.162368Z","iopub.execute_input":"2025-05-26T17:48:42.162541Z","iopub.status.idle":"2025-05-26T17:49:05.780494Z","shell.execute_reply.started":"2025-05-26T17:48:42.162526Z","shell.execute_reply":"2025-05-26T17:49:05.779956Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b795084261e04273ac69d6bc75adf3c6"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"### Collating","metadata":{}},{"cell_type":"code","source":"def collate_fn(batch):\n    input_ids = torch.tensor([sample['input_ids'] for sample in batch], dtype=torch.long)\n    attention_mask = torch.tensor([sample['attention_mask'] for sample in batch], dtype=torch.long)\n    labels = torch.tensor([sample['labels'] for sample in batch], dtype=torch.long)\n    return {\n        'input_ids': input_ids,\n        'attention_mask': attention_mask,\n        'labels': labels\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:49:05.781156Z","iopub.execute_input":"2025-05-26T17:49:05.781421Z","iopub.status.idle":"2025-05-26T17:49:05.785509Z","shell.execute_reply.started":"2025-05-26T17:49:05.781404Z","shell.execute_reply":"2025-05-26T17:49:05.784797Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Batching","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:49:05.787739Z","iopub.execute_input":"2025-05-26T17:49:05.788056Z","iopub.status.idle":"2025-05-26T17:49:05.825002Z","shell.execute_reply.started":"2025-05-26T17:49:05.788041Z","shell.execute_reply":"2025-05-26T17:49:05.824327Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### Defining metrics","metadata":{}},{"cell_type":"code","source":"from summac.model_summac import SummaCConv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:49:05.825633Z","iopub.execute_input":"2025-05-26T17:49:05.825833Z","iopub.status.idle":"2025-05-26T17:49:06.259127Z","shell.execute_reply.started":"2025-05-26T17:49:05.825819Z","shell.execute_reply":"2025-05-26T17:49:06.258545Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"summac_model = SummaCConv(\n    granularity=\"sentence\",\n    models=[\"vitc\"],\n    device=DEVICE,\n    start_file=None,\n    use_con=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:49:06.260129Z","iopub.execute_input":"2025-05-26T17:49:06.260352Z","iopub.status.idle":"2025-05-26T17:49:06.265004Z","shell.execute_reply.started":"2025-05-26T17:49:06.260335Z","shell.execute_reply":"2025-05-26T17:49:06.264489Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_losses = []\nval_losses = []\nsummac_scores = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:49:06.265664Z","iopub.execute_input":"2025-05-26T17:49:06.265853Z","iopub.status.idle":"2025-05-26T17:49:06.279445Z","shell.execute_reply.started":"2025-05-26T17:49:06.265838Z","shell.execute_reply":"2025-05-26T17:49:06.278743Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### Optimizer, scheduler, accelerator","metadata":{}},{"cell_type":"code","source":"# Optimizer and scheduler\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR)\nnum_training_steps = EPOCHS * len(train_loader)\nlr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n\n# Accelerator\naccelerator = Accelerator(mixed_precision=\"fp16\")\nmodel, optimizer, train_loader, val_loader, lr_scheduler = accelerator.prepare(\n    model, optimizer, train_loader, val_loader, lr_scheduler\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:49:06.280273Z","iopub.execute_input":"2025-05-26T17:49:06.280526Z","iopub.status.idle":"2025-05-26T17:49:06.390424Z","shell.execute_reply.started":"2025-05-26T17:49:06.280503Z","shell.execute_reply":"2025-05-26T17:49:06.389861Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"### Final preparations","metadata":{}},{"cell_type":"markdown","source":"### Generating text for validation","metadata":{}},{"cell_type":"code","source":"def generate_text(input_ids, attention_mask):\n    outputs = model.generate(\n        input_ids=input_ids, \n        attention_mask=attention_mask, \n        max_new_tokens=64, \n        pad_token_id=tokenizer.pad_token_id, \n        eos_token_id=tokenizer.eos_token_id, \n        num_beams=4,  # beam search \n        early_stopping=True, \n    ) \n    return tokenizer.batch_decode(outputs, skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:49:06.391049Z","iopub.execute_input":"2025-05-26T17:49:06.391299Z","iopub.status.idle":"2025-05-26T17:49:06.395285Z","shell.execute_reply.started":"2025-05-26T17:49:06.391283Z","shell.execute_reply":"2025-05-26T17:49:06.394589Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### Training loop","metadata":{}},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n    model.train()\n    total_train_loss = 0\n    for batch in tqdm(train_loader):\n        batch = {k: v.to(model.device) for k, v in batch.items()}\n    \n        outputs = model(\n            input_ids=batch[\"input_ids\"],\n            attention_mask=batch[\"attention_mask\"],\n            labels=batch[\"labels\"]\n        )\n        loss = outputs.loss\n        accelerator.backward(loss)\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        total_train_loss += loss.item()\n\n    avg_train_loss = total_train_loss / len(train_loader)\n    train_losses.append(avg_train_loss)\n\n    model.eval()\n    total_val_loss = 0\n    preds = []\n    sources = []\n    with torch.no_grad():\n        for batch in tqdm(val_loader):\n            batch = {k: v.to(model.device) for k, v in batch.items()}\n    \n            outputs = model(\n                input_ids=batch[\"input_ids\"],\n                attention_mask=batch[\"attention_mask\"],\n                labels=batch[\"labels\"]\n            )\n            loss = outputs.loss\n            total_val_loss += loss.item()\n\n            generated_texts = generate_text(batch[\"input_ids\"], batch[\"attention_mask\"])\n            preds.extend(generated_texts)\n            for input_id in batch[\"input_ids\"]:\n                sources.append(tokenizer.decode(input_id, skip_special_tokens=True))\n\n    avg_val_loss = total_val_loss / len(val_loader)\n    val_losses.append(avg_val_loss)\n\n    summac_result = summac_model.score(sources, preds, batch_size=8)\n    summac_score = np.mean(summac_result[\"scores\"])\n    summac_scores.append(summac_score)\n\n    print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | SummaC: {summac_score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:49:06.396069Z","iopub.execute_input":"2025-05-26T17:49:06.396316Z","execution_failed":"2025-05-26T19:00:41.393Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████▏    | 1156/2250 [26:46<25:19,  1.39s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"### Saving model","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(OUTPUT_DIR)\ntokenizer.save_pretrained(OUTPUT_DIR)\nprint(f\"Model is saved: {OUTPUT_DIR}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-26T19:00:41.393Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Graphical visualization","metadata":{}},{"cell_type":"code","source":"epochs = np.arange(1, EPOCHS+1)\n\nplt.figure(figsize=(12, 8))\n\n# Training and validation losses graphics\nplt.subplot(2, 2, 1)\nplt.plot(epochs, train_losses, label=\"Train Loss\")\nplt.plot(epochs, val_losses, label=\"Val Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.title(\"Loss\")\n\n# SummaC score graphic\nplt.subplot(2, 2, 2)\nplt.plot(epochs, summac_scores, label=\"SummaC\", color=\"orange\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Score\")\nplt.legend()\nplt.title(\"SummaC\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-26T19:00:41.393Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Pushing results to HF","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import HfApi","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-26T19:00:41.393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"api = HfApi()\n# Creating repository\napi.create_repo(repo_id=\"H1merka/InternVL2_5-4B-QLoRA-LLM-RussianSummarization\", exist_ok=True, token=\"<token>\")\n\n# Uploading files\napi.upload_folder(\n    folder_path=\"./finetuned_model\",\n    path_in_repo=\"\",\n    repo_id=\"H1merka/InternVL2_5-4B-QLoRA-LLM-RussianSummarization\",\n    repo_type=\"model\",\n    token=\"<token>\"\n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-26T19:00:41.393Z"}},"outputs":[],"execution_count":null}]}