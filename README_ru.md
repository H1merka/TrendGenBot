# TrendGenBot

[\[üìÇ GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –º–æ–¥–µ–ª–∏\]](https://github.com/H1merka/InternVL2_5-4B-QLoRA-LLM-RussianSummarization)  [\[ü§ó HF —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –º–æ–¥–µ–ª–∏\]](https://huggingface.co/H1merka/InternVL2_5-4B-QLoRA-LLM-RussianSummarization) [\[üìÇ GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è\]](https://github.com/H1merka/TrendGenBot) [\[VK –≥—Ä—É–ø–ø–∞ —Å —á–∞—Ç-–±–æ—Ç–æ–º\]](https://vk.com/club230649268)

## –í–≤–µ–¥–µ–Ω–∏–µ

–í–ö —á–∞—Ç-–±–æ—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É –¥–ª—è —Å–æ–æ–±—â–µ—Å—Ç–≤ –í–ö —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º –ò–ò-–∞–≥–µ–Ω—Ç–∞


## –û–ø–∏—Å–∞–Ω–∏–µ


–ò–ò-–∞–≥–µ–Ω—Ç –ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ —á–∞—Ç-–±–æ—Ç–∞ –∫ –≥—Ä—É–ø–ø–µ –í–ö–æ–Ω—Ç–∞–∫—Ç–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –∫–æ–Ω—Ç–µ–Ω—Ç-–ø–ª–∞–Ω—É –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –ø–æ—Å—Ç–æ–≤.

–ß–∞—Ç-–±–æ—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç [InternVL2_5-4B](https://huggingface.co/OpenGVLab/InternVL2_5-4B) –º–æ–¥–µ–ª—å —Å LoRA [–∞–¥–∞–ø—Ç–µ—Ä–æ–º](https://huggingface.co/H1merka/InternVL2_5-4B-QLoRA-LLM-RussianSummarization) –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

[–ö–ª—é—á –¥–æ—Å—Ç—É–ø–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è](https://dev.vk.com/ru/api/access-token/authcode-flow-user) –∏ [–∫–ª—é—á –¥–æ—Å—Ç—É–ø–∞ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞](https://dev.vk.com/ru/api/access-token/community-token/in-community-settings) –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

–ß–∞—Å—Ç–∏—á–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ VK ID –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Å PKCE flow

## –õ–∏—Ü–µ–Ω–∑–∏—è

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –≤—ã–ø—É—â–µ–Ω –ø–æ–¥ –ª–∏—Ü–µ–Ω–∑–∏–µ–π MIT. –í —ç—Ç–æ–º –ø—Ä–æ–µ–∫—Ç–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å InternVL2_5-4B, –∫–æ—Ç–æ—Ä–∞—è –ª–∏—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–∞ –ø–æ–¥ MIT.

## –ö–æ–º–∞–Ω–¥–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
GitHub: [https://github.com/H1merka](https://github.com/H1merka)

## –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

–ï—Å–ª–∏ –≤—ã —Å–æ—á—Ç–µ—Ç–µ —ç—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –ø–æ–ª–µ–∑–Ω—ã–º, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:

```BibTeX
@article{chen2024expanding,
  title={Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling},
  author={Chen, Zhe and Wang, Weiyun and Cao, Yue and Liu, Yangzhou and Gao, Zhangwei and Cui, Erfei and Zhu, Jinguo and Ye, Shenglong and Tian, Hao and Liu, Zhaoyang and others},
  journal={arXiv preprint arXiv:2412.05271},
  year={2024}
}
@article{gao2024mini,
  title={Mini-internvl: A flexible-transfer pocket multimodal model with 5\% parameters and 90\% performance},
  author={Gao, Zhangwei and Chen, Zhe and Cui, Erfei and Ren, Yiming and Wang, Weiyun and Zhu, Jinguo and Tian, Hao and Ye, Shenglong and He, Junjun and Zhu, Xizhou and others},
  journal={arXiv preprint arXiv:2410.16261},
  year={2024}
}
@article{chen2024far,
  title={How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites},
  author={Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and others},
  journal={arXiv preprint arXiv:2404.16821},
  year={2024}
}
@inproceedings{chen2024internvl,
  title={Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24185--24198},
  year={2024}
}
```
